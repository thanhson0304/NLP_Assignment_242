{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70286db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from evaluate import load\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d7ffd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('rajpurkar/squad')\n",
    "split = dataset['validation'].train_test_split(test_size=0.5, seed=42)\n",
    "raw_datasets = {\n",
    "    'train': dataset['train'],\n",
    "    'validation': split['train'],\n",
    "    'test': split['test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46af2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "max_length = 384\n",
    "doc_stride = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad38ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples['question'], examples['context'],\n",
    "        truncation='only_second',\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "\n",
    "    overflow_to_sample_mapping = tokenized.pop('overflow_to_sample_mapping')\n",
    "    offset_mapping = tokenized.pop('offset_mapping')\n",
    "\n",
    "    tokenized['start_positions'] = []\n",
    "    tokenized['end_positions'] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        sample_idx = overflow_to_sample_mapping[i]\n",
    "        answers = examples['answers'][sample_idx]\n",
    "        cls_index = tokenized['input_ids'][i].index(tokenizer.cls_token_id)\n",
    "\n",
    "        if len(answers['answer_start']) == 0:\n",
    "            tokenized['start_positions'].append(cls_index)\n",
    "            tokenized['end_positions'].append(cls_index)\n",
    "        else:\n",
    "            start_char = answers['answer_start'][0]\n",
    "            end_char = start_char + len(answers['text'][0])\n",
    "            sequence_ids = tokenized.sequence_ids(i)\n",
    "\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "            token_end_index = len(tokenized['input_ids'][i]) - 1\n",
    "            while sequence_ids[token_end_index] != 1:\n",
    "                token_end_index -= 1\n",
    "\n",
    "            if offsets[token_start_index][0] > end_char or offsets[token_end_index][1] < start_char:\n",
    "                tokenized['start_positions'].append(cls_index)\n",
    "                tokenized['end_positions'].append(cls_index)\n",
    "            else:\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized['start_positions'].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized['end_positions'].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a7a3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bd5b1b648e45df988714a18e106b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = {k: raw_datasets[k].map(\n",
    "    prepare_features,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[k].column_names\n",
    ") for k in ['train', 'validation', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6703eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataset[idx]\n",
    "        return {\n",
    "            'input_ids': torch.tensor(row['input_ids']),\n",
    "            'attention_mask': torch.tensor(row['attention_mask']),\n",
    "            'start_positions': torch.tensor(row['start_positions']),\n",
    "            'end_positions': torch.tensor(row['end_positions'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba5d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QADataset(tokenized_datasets['train'])\n",
    "val_dataset   = QADataset(tokenized_datasets['validation'])\n",
    "test_dataset  = QADataset(tokenized_datasets['test'])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d139c44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModelForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.QUESTION_ANS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['query', 'value', 'dense']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef10aee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForQuestionAnswering(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForQuestionAnswering(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (qa_outputs): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_peft_model(base_model, lora_config)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora_' not in name:\n",
    "        param.requires_grad = False\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599ebf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10bao\\AppData\\Local\\Temp\\ipykernel_18860\\3277783042.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "num_epochs = 3\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=total_steps//10, num_training_steps=total_steps)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "metric = load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dd2e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for step, batch in enumerate(train_loader, start=1):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_pos = batch['start_positions'].to(device)\n",
    "        end_pos = batch['end_positions'].to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "            loss = (criterion(start_logits, start_pos) + criterion(end_logits, end_pos)) / 2\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Epoch {epoch} Step {step}/{len(train_loader)} - Loss: {running_loss/step:.4f}\")\n",
    "\n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52ae9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_epoch(data_loader, raw_data):\n",
    "    model.eval()\n",
    "    eval_loss = 0.0\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_pos = batch['start_positions'].to(device)\n",
    "        end_pos = batch['end_positions'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "        eval_loss += ((criterion(start_logits, start_pos) + criterion(end_logits, end_pos)) / 2).item()\n",
    "\n",
    "        for b in range(len(input_ids)):\n",
    "            start_idx = torch.argmax(start_logits[b]).item()\n",
    "            end_idx = torch.argmax(end_logits[b]).item()\n",
    "            if start_idx > end_idx:\n",
    "                answer = \"\"\n",
    "            else:\n",
    "                tokens = input_ids[b][start_idx:end_idx+1]\n",
    "                answer = tokenizer.decode(tokens, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "            sample_index = i * data_loader.batch_size + b\n",
    "            if sample_index < len(raw_data):\n",
    "                predictions.append({\"id\": raw_data[sample_index][\"id\"], \"prediction_text\": answer})\n",
    "                references.append({\"id\": raw_data[sample_index][\"id\"], \"answers\": raw_data[sample_index][\"answers\"]})\n",
    "\n",
    "    metrics = metric.compute(predictions=predictions, references=references)\n",
    "    return eval_loss / len(data_loader), metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf1d4d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Epoch 1/1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10bao\\AppData\\Local\\Temp\\ipykernel_18860\\3209567763.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 100/11066 - Loss: 5.9886\n",
      "Epoch 1 Step 200/11066 - Loss: 5.9789\n",
      "Epoch 1 Step 300/11066 - Loss: 5.9638\n",
      "Epoch 1 Step 400/11066 - Loss: 5.9155\n",
      "Epoch 1 Step 500/11066 - Loss: 5.8008\n",
      "Epoch 1 Step 600/11066 - Loss: 5.6334\n",
      "Epoch 1 Step 700/11066 - Loss: 5.4599\n",
      "Epoch 1 Step 800/11066 - Loss: 5.3055\n",
      "Epoch 1 Step 900/11066 - Loss: 5.1528\n",
      "Epoch 1 Step 1000/11066 - Loss: 5.0237\n",
      "Epoch 1 Step 1100/11066 - Loss: 4.9138\n",
      "Epoch 1 Step 1200/11066 - Loss: 4.8116\n",
      "Epoch 1 Step 1300/11066 - Loss: 4.7144\n",
      "Epoch 1 Step 1400/11066 - Loss: 4.6332\n",
      "Epoch 1 Step 1500/11066 - Loss: 4.5424\n",
      "Epoch 1 Step 1600/11066 - Loss: 4.4496\n",
      "Epoch 1 Step 1700/11066 - Loss: 4.3594\n",
      "Epoch 1 Step 1800/11066 - Loss: 4.2726\n",
      "Epoch 1 Step 1900/11066 - Loss: 4.1920\n",
      "Epoch 1 Step 2000/11066 - Loss: 4.1132\n",
      "Epoch 1 Step 2100/11066 - Loss: 4.0445\n",
      "Epoch 1 Step 2200/11066 - Loss: 3.9776\n",
      "Epoch 1 Step 2300/11066 - Loss: 3.9089\n",
      "Epoch 1 Step 2400/11066 - Loss: 3.8481\n",
      "Epoch 1 Step 2500/11066 - Loss: 3.7880\n",
      "Epoch 1 Step 2600/11066 - Loss: 3.7332\n",
      "Epoch 1 Step 2700/11066 - Loss: 3.6840\n",
      "Epoch 1 Step 2800/11066 - Loss: 3.6378\n",
      "Epoch 1 Step 2900/11066 - Loss: 3.5906\n",
      "Epoch 1 Step 3000/11066 - Loss: 3.5491\n",
      "Epoch 1 Step 3100/11066 - Loss: 3.5096\n",
      "Epoch 1 Step 3200/11066 - Loss: 3.4696\n",
      "Epoch 1 Step 3300/11066 - Loss: 3.4347\n",
      "Epoch 1 Step 3400/11066 - Loss: 3.4008\n",
      "Epoch 1 Step 3500/11066 - Loss: 3.3647\n",
      "Epoch 1 Step 3600/11066 - Loss: 3.3344\n",
      "Epoch 1 Step 3700/11066 - Loss: 3.3033\n",
      "Epoch 1 Step 3800/11066 - Loss: 3.2726\n",
      "Epoch 1 Step 3900/11066 - Loss: 3.2442\n",
      "Epoch 1 Step 4000/11066 - Loss: 3.2169\n",
      "Epoch 1 Step 4100/11066 - Loss: 3.1916\n",
      "Epoch 1 Step 4200/11066 - Loss: 3.1637\n",
      "Epoch 1 Step 4300/11066 - Loss: 3.1388\n",
      "Epoch 1 Step 4400/11066 - Loss: 3.1113\n",
      "Epoch 1 Step 4500/11066 - Loss: 3.0886\n",
      "Epoch 1 Step 4600/11066 - Loss: 3.0662\n",
      "Epoch 1 Step 4700/11066 - Loss: 3.0466\n",
      "Epoch 1 Step 4800/11066 - Loss: 3.0257\n",
      "Epoch 1 Step 4900/11066 - Loss: 3.0050\n",
      "Epoch 1 Step 5000/11066 - Loss: 2.9871\n",
      "Epoch 1 Step 5100/11066 - Loss: 2.9680\n",
      "Epoch 1 Step 5200/11066 - Loss: 2.9480\n",
      "Epoch 1 Step 5300/11066 - Loss: 2.9312\n",
      "Epoch 1 Step 5400/11066 - Loss: 2.9131\n",
      "Epoch 1 Step 5500/11066 - Loss: 2.8931\n",
      "Epoch 1 Step 5600/11066 - Loss: 2.8774\n",
      "Epoch 1 Step 5700/11066 - Loss: 2.8597\n",
      "Epoch 1 Step 5800/11066 - Loss: 2.8444\n",
      "Epoch 1 Step 5900/11066 - Loss: 2.8298\n",
      "Epoch 1 Step 6000/11066 - Loss: 2.8144\n",
      "Epoch 1 Step 6100/11066 - Loss: 2.8001\n",
      "Epoch 1 Step 6200/11066 - Loss: 2.7866\n",
      "Epoch 1 Step 6300/11066 - Loss: 2.7741\n",
      "Epoch 1 Step 6400/11066 - Loss: 2.7628\n",
      "Epoch 1 Step 6500/11066 - Loss: 2.7512\n",
      "Epoch 1 Step 6600/11066 - Loss: 2.7382\n",
      "Epoch 1 Step 6700/11066 - Loss: 2.7264\n",
      "Epoch 1 Step 6800/11066 - Loss: 2.7128\n",
      "Epoch 1 Step 6900/11066 - Loss: 2.7004\n",
      "Epoch 1 Step 7000/11066 - Loss: 2.6887\n",
      "Epoch 1 Step 7100/11066 - Loss: 2.6783\n",
      "Epoch 1 Step 7200/11066 - Loss: 2.6657\n",
      "Epoch 1 Step 7300/11066 - Loss: 2.6540\n",
      "Epoch 1 Step 7400/11066 - Loss: 2.6426\n",
      "Epoch 1 Step 7500/11066 - Loss: 2.6307\n",
      "Epoch 1 Step 7600/11066 - Loss: 2.6196\n",
      "Epoch 1 Step 7700/11066 - Loss: 2.6102\n",
      "Epoch 1 Step 7800/11066 - Loss: 2.6012\n",
      "Epoch 1 Step 7900/11066 - Loss: 2.5919\n",
      "Epoch 1 Step 8000/11066 - Loss: 2.5819\n",
      "Epoch 1 Step 8100/11066 - Loss: 2.5733\n",
      "Epoch 1 Step 8200/11066 - Loss: 2.5640\n",
      "Epoch 1 Step 8300/11066 - Loss: 2.5558\n",
      "Epoch 1 Step 8400/11066 - Loss: 2.5470\n",
      "Epoch 1 Step 8500/11066 - Loss: 2.5389\n",
      "Epoch 1 Step 8600/11066 - Loss: 2.5311\n",
      "Epoch 1 Step 8700/11066 - Loss: 2.5227\n",
      "Epoch 1 Step 8800/11066 - Loss: 2.5141\n",
      "Epoch 1 Step 8900/11066 - Loss: 2.5052\n",
      "Epoch 1 Step 9000/11066 - Loss: 2.4979\n",
      "Epoch 1 Step 9100/11066 - Loss: 2.4892\n",
      "Epoch 1 Step 9200/11066 - Loss: 2.4812\n",
      "Epoch 1 Step 9300/11066 - Loss: 2.4739\n",
      "Epoch 1 Step 9400/11066 - Loss: 2.4672\n",
      "Epoch 1 Step 9500/11066 - Loss: 2.4607\n",
      "Epoch 1 Step 9600/11066 - Loss: 2.4546\n",
      "Epoch 1 Step 9700/11066 - Loss: 2.4478\n",
      "Epoch 1 Step 9800/11066 - Loss: 2.4397\n",
      "Epoch 1 Step 9900/11066 - Loss: 2.4323\n",
      "Epoch 1 Step 10000/11066 - Loss: 2.4251\n",
      "Epoch 1 Step 10100/11066 - Loss: 2.4181\n",
      "Epoch 1 Step 10200/11066 - Loss: 2.4124\n",
      "Epoch 1 Step 10300/11066 - Loss: 2.4066\n",
      "Epoch 1 Step 10400/11066 - Loss: 2.3997\n",
      "Epoch 1 Step 10500/11066 - Loss: 2.3935\n",
      "Epoch 1 Step 10600/11066 - Loss: 2.3877\n",
      "Epoch 1 Step 10700/11066 - Loss: 2.3820\n",
      "Epoch 1 Step 10800/11066 - Loss: 2.3764\n",
      "Epoch 1 Step 10900/11066 - Loss: 2.3703\n",
      "Epoch 1 Step 11000/11066 - Loss: 2.3656\n",
      "Train Loss: 2.3619\n",
      "Val Loss: 1.6585 | EM: 0.49 | F1: 1.05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f\"\\n=== Epoch {epoch}/{num_epochs} ===\")\n",
    "    train_loss = train_epoch(epoch)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    val_loss, val_metrics = eval_epoch(val_loader, raw_datasets['validation'])\n",
    "    print(f\"Val Loss: {val_loss:.4f} | EM: {val_metrics['exact_match']:.2f} | F1: {val_metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b6126f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Performance ===\n",
      "Test Loss: 1.6238 | EM: 1.17 | F1: 1.84\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Test Performance ===\")\n",
    "test_loss, test_metrics = eval_epoch(test_loader, raw_datasets['test'])\n",
    "print(f\"Test Loss: {test_loss:.4f} | EM: {test_metrics['exact_match']:.2f} | F1: {test_metrics['f1']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf009a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcdedf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
