{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64d2a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.6.0)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.6.0)\n",
      "Requirement already satisfied: trl in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.17.0)\n",
      "Requirement already satisfied: rouge_score in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/quan0207/Library/Python/3.13/lib/python/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (80.4.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: psutil in /Users/quan0207/Library/Python/3.13/lib/python/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rouge_score) (2.2.2)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/quan0207/Library/Python/3.13/lib/python/site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from nltk->rouge_score) (8.2.0)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from nltk->rouge_score) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/quan0207/Library/Python/3.13/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/quan0207/Library/Python/3.13/lib/python/site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers datasets torch accelerate trl rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e766a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    GPT2Config,\n",
    "    GPT2Tokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    GPT2LMHeadModel\n",
    ")\n",
    "from trl import PPOConfig, PPOTrainer\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31860456",
   "metadata": {},
   "source": [
    "# 1) Model w/ Value Head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f4a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2WithValueHead(nn.Module):\n",
    "    def __init__(self, base_model_name=\"gpt2\"):\n",
    "        super().__init__()\n",
    "        self.config = GPT2Config.from_pretrained(base_model_name)\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        self.transformer = GPT2LMHeadModel.from_pretrained(\n",
    "            base_model_name, config=self.config\n",
    "        )\n",
    "        self.value_head = nn.Linear(self.config.hidden_size, 1, bias=False)\n",
    "        self.value_head.weight.data.normal_(\n",
    "            0.0, self.config.initializer_range\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "        lm_out = self.transformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            output_hidden_states=True,\n",
    "            **kwargs\n",
    "        )\n",
    "        hidden = lm_out.hidden_states[-1]                # (B, T, H)\n",
    "        values = self.value_head(hidden).squeeze(-1)      # (B, T)\n",
    "        return {\n",
    "            \"logits\": lm_out.logits,\n",
    "            \"loss\": lm_out.loss,\n",
    "            \"values\": values,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb54bfe",
   "metadata": {},
   "source": [
    "\n",
    "# 2) Data, Tokenizer, Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0709160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:100000]\")\n",
    "val_ds  = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation[:10000]\")\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "class MyCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad = DataCollatorWithPadding(tokenizer)\n",
    "    def __call__(self, features):\n",
    "        refs = [f.pop(\"refs\") for f in features]\n",
    "        batch = self.pad(features)\n",
    "        batch[\"refs\"] = refs\n",
    "        return batch\n",
    "\n",
    "data_collator = MyCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2f3ab",
   "metadata": {},
   "source": [
    "# 3) Reward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e92e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RougeRewardModel(nn.Module):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "\n",
    "    def forward(self, prompts, response_toks, refs, **kwargs):\n",
    "        hyps = self.tokenizer.batch_decode(response_toks, skip_special_tokens=True)\n",
    "        scores = [\n",
    "            self.scorer.score(r, h)[\"rougeL\"].fmeasure\n",
    "            for r, h in zip(refs, hyps)\n",
    "        ]\n",
    "        r = torch.tensor(scores, dtype=torch.float32, device=response_toks.device)\n",
    "        # normalize\n",
    "        return (r - r.mean()) / (r.std() + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfc855",
   "metadata": {},
   "source": [
    "\n",
    "# 4) PPO Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efd4c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = PPOConfig(\n",
    "    learning_rate=1.4e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_ppo_epochs=4,\n",
    "    cliprange=0.2,\n",
    "    cliprange_value=0.2,\n",
    "    vf_coef=0.1,\n",
    "    kl_coef=0.1,\n",
    "    gamma=1.0,\n",
    "    lam=0.95,\n",
    "    num_sample_generations=10,\n",
    "    response_length=64,\n",
    "    output_dir=\"gpt2-ppo-summarization\",\n",
    "    overwrite_output_dir=True,\n",
    "    logging_dir=\"runs/ppo_summarization\",\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aabfd28",
   "metadata": {},
   "source": [
    "# 5) Instantiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b58f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2WithValueHead(\"gpt2\")\n",
    "ref_model = GPT2WithValueHead(\"gpt2\")\n",
    "ref_model.load_state_dict(model.state_dict())\n",
    "ref_model.eval()\n",
    "\n",
    "model.generation_config = model.transformer.generation_config\n",
    "ref_model.generation_config = ref_model.transformer.generation_config\n",
    "\n",
    "reward_model = RougeRewardModel(tokenizer)\n",
    "value_model = model.transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c697fd9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2bf996",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(\n",
    "    args=ppo_config,\n",
    "    processing_class=tokenizer,\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    reward_model=reward_model,\n",
    "    train_dataset=train_ds,\n",
    "    value_model=value_model,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=val_ds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4396cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===training policy===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['article', 'highlights', 'id']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m trainer.save_model(\u001b[33m\"\u001b[39m\u001b[33mgpt2-ppo-summarization\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m tokenizer.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33mgpt2-ppo-summarization\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/trl/trainer/ppo_trainer.py:411\u001b[39m, in \u001b[36mPPOTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, args.num_total_batches + \u001b[32m1\u001b[39m):\n\u001b[32m    410\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.episode += \u001b[32m1\u001b[39m * args.batch_size\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     data = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    412\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    413\u001b[39m         queries = data[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/trl/trainer/ppo_trainer.py:358\u001b[39m, in \u001b[36mPPOTrainer.train.<locals>.repeat_generator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrepeat_generator\u001b[39m():\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m dataloader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/accelerate/data_loader.py:566\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     current_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/data/data_collator.py:272\u001b[39m, in \u001b[36mDataCollatorWithPadding.__call__\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     batch = \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m    281\u001b[39m         batch[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m] = batch[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/data/data_collator.py:67\u001b[39m, in \u001b[36mpad_without_fast_tokenizer_warning\u001b[39m\u001b[34m(tokenizer, *pad_args, **pad_kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m tokenizer.deprecation_warnings[\u001b[33m\"\u001b[39m\u001b[33mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     padded = \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpad_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpad_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[32m     70\u001b[39m     tokenizer.deprecation_warnings[\u001b[33m\"\u001b[39m\u001b[33mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[33m\"\u001b[39m] = warning_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3324\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.pad\u001b[39m\u001b[34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[39m\n\u001b[32m   3322\u001b[39m \u001b[38;5;66;03m# The model's main input name, usually `input_ids`, has been passed for padding\u001b[39;00m\n\u001b[32m   3323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m encoded_inputs:\n\u001b[32m-> \u001b[39m\u001b[32m3324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3325\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3326\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(encoded_inputs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   3327\u001b[39m     )\n\u001b[32m   3329\u001b[39m required_input = encoded_inputs[\u001b[38;5;28mself\u001b[39m.model_input_names[\u001b[32m0\u001b[39m]]\n\u001b[32m   3331\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(required_input, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) == \u001b[32m0\u001b[39m):\n",
      "\u001b[31mValueError\u001b[39m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['article', 'highlights', 'id']"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"gpt2-ppo-summarization\")\n",
    "tokenizer.save_pretrained(\"gpt2-ppo-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "all_scores = []\n",
    "for i in range(0, len(val_ds), 4):\n",
    "    batch = val_ds[i : i + 4]\n",
    "    arts = batch[\"article\"]\n",
    "    refs = batch[\"highlights\"]\n",
    "    prompts = [f\"Summarize:\\n{a}\\nTL;DR:\" for a in arts]\n",
    "    toks = trainer.generate(prompts, max_length=64)\n",
    "    hyps = tokenizer.batch_decode(toks, skip_special_tokens=True)\n",
    "    for ref, hyp in zip(refs, hyps):\n",
    "        all_scores.append(\n",
    "            rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "            .score(ref, hyp)[\"rougeL\"].fmeasure\n",
    "        )\n",
    "\n",
    "avg = sum(all_scores) / len(all_scores)\n",
    "print(f\"\\n>> Final Validation ROUGE-L: {avg:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
